{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# Model parameters\n",
    "reg = 1000\n",
    "max_depth = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist = list()\n",
    "all_decades = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Get data for each decade\n",
    "for decade in all_decades:\n",
    "    df = pd.read_csv(f\"decade{decade}.csv\")\n",
    "    datalist.append({\n",
    "        \"X\": df.drop(columns=[\"warstds\"]),\n",
    "        \"y\": df[\"warstds\"]\n",
    "    })\n",
    "\n",
    "all_data = dict()\n",
    "\n",
    "# Get train-test splits for each decade\n",
    "for decade, data in enumerate(datalist):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data[\"X\"], data[\"y\"], test_size=0.3, stratify=data[\"y\"])\n",
    "    all_data[f\"{decade+1}_tr\"] = {\n",
    "        \"X\": X_train,\n",
    "        \"y\": y_train\n",
    "    }\n",
    "    all_data[f\"{decade+1}_test\"] = {\n",
    "        \"X\": X_train,\n",
    "        \"y\": y_train\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['1_tr', '1_test', '2_tr', '2_test', '3_tr', '3_test', '4_tr', '4_test', '5_tr', '5_test'])"
      ]
     },
     "metadata": {},
     "execution_count": 283
    }
   ],
   "source": [
    "all_data.keys()"
   ]
  },
  {
   "source": [
    "# Baseline: train on all decades, predict on each decade individually"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Decade 1 -- Test Scores for Logistic Regression: 0.0967741935483871, Random Forest: 0.6\nDecade 2 -- Test Scores for Logistic Regression: 0.0404040404040404, Random Forest: 0.1111111111111111\nDecade 3 -- Test Scores for Logistic Regression: 0.03805496828752642, Random Forest: 0.1111111111111111\nDecade 4 -- Test Scores for Logistic Regression: 0.03544303797468354, Random Forest: 0.13333333333333333\nDecade 5 -- Test Scores for Logistic Regression: 0.06626506024096385, Random Forest: 0.9500000000000001\n"
     ]
    }
   ],
   "source": [
    "# Train on all decade training sets\n",
    "log_reg = LogisticRegression(C=reg, class_weight=\"balanced\")\n",
    "rdm_for = RandomForestClassifier(max_depth=max_depth, class_weight=\"balanced\")\n",
    "for decade in all_decades:\n",
    "    train_X = all_data[f\"{decade}_tr\"][\"X\"]\n",
    "    train_y = all_data[f\"{decade}_tr\"][\"y\"]\n",
    "    log_reg.fit(train_X, train_y)\n",
    "    rdm_for.fit(train_X, train_y)\n",
    "\n",
    "# Test on each decade test set individually\n",
    "for decade in all_decades:\n",
    "    test_X = all_data[f\"{decade}_test\"][\"X\"]\n",
    "    test_y = all_data[f\"{decade}_test\"][\"y\"]\n",
    "    log_reg_score = f1_score(test_y, log_reg.predict(test_X))\n",
    "    rdm_for_score = f1_score(test_y, rdm_for.predict(test_X))\n",
    "    print(\"Decade {2} -- Test Scores for Logistic Regression: {0}, Random Forest: {1}\".format(log_reg_score, rdm_for_score, decade))"
   ]
  },
  {
   "source": [
    "# Exp 1: Predicting the past. Train on 1960-2000, test on 1945-1959"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Train on all training set but the first\n",
    "train_X = pd.concat([\n",
    "    all_data[\"2_tr\"][\"X\"],\n",
    "    all_data[\"3_tr\"][\"X\"],\n",
    "    all_data[\"4_tr\"][\"X\"],\n",
    "    all_data[\"5_tr\"][\"X\"]\n",
    "])\n",
    "\n",
    "train_y = pd.concat([\n",
    "    all_data[\"2_tr\"][\"y\"],\n",
    "    all_data[\"3_tr\"][\"y\"],\n",
    "    all_data[\"4_tr\"][\"y\"],\n",
    "    all_data[\"5_tr\"][\"y\"]\n",
    "])\n",
    "\n",
    "# Test on first test set\n",
    "test_X = all_data[\"1_test\"][\"X\"]\n",
    "test_y = all_data[\"1_test\"][\"y\"]\n",
    "\n",
    "log_reg = LogisticRegression(C=reg, class_weight=\"balanced\").fit(train_X, train_y)\n",
    "rdm_for = RandomForestClassifier(max_depth=max_depth, class_weight=\"balanced\").fit(train_X, train_y)\n",
    "log_reg_score = log_reg.score(test_X, test_y)\n",
    "rdm_for_score = rdm_for.score(test_X, test_y)\n",
    "log_reg_f1score = f1_score(test_y, log_reg.predict(test_X))\n",
    "rdm_for_f1score = f1_score(test_y, rdm_for.predict(test_X))\n",
    "log_reg_auc = roc_auc_score(test_y, log_reg.predict_proba(test_X)[:, 1])\n",
    "rdm_for_auc = roc_auc_score(test_y, rdm_for.predict_proba(test_X)[:, 1])\n",
    "\n",
    "print(f\"Decade 1:\")\n",
    "print(\"Test on 1, LR: {0}, RF: {1}\".format(round(log_reg_score, 5), round(rdm_for_score, 5)))\n",
    "print(\"F1 for LR: {0}, RF: {1}\".format(round(log_reg_f1score, 4), round(rdm_for_f1score, 4)))\n",
    "print(\"AUC for LR: {0}, RF: {1}\\n\".format(round(log_reg_auc, 4), round(rdm_for_auc, 4)))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 294,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Decade 1:\nTest on 1, LR: 0.88956, RF: 0.97573\nF1 for LR: 0.1651, RF: 0.5238\nAUC for LR: 0.8303, RF: 0.9931\n\n"
     ]
    }
   ]
  },
  {
   "source": [
    "# Exp 2: Predicting in-between timeframes.\n",
    "- Train on 1945-1959 and 1970-2000, test on 1960-1969\n",
    "- Train on 1945-1969 and 1980-2000, test on 1970-1979\n",
    "- Train on 1945-1979 and 1990-2000, test on 1980-1989"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Decade 2:\n",
      "Test on 2, LR: 0.35962, RF: 0.98805\n",
      "F1 for LR: 0.0429, RF: 0.6154\n",
      "AUC for LR: 0.4977, RF: 0.9437\n",
      "\n",
      "Decade 3:\n",
      "Test on 3, LR: 0.2886, RF: 0.98688\n",
      "F1 for LR: 0.0382, RF: 0.48\n",
      "AUC for LR: 0.6042, RF: 0.9925\n",
      "\n",
      "Decade 4:\n",
      "Test on 4, LR: 0.66066, RF: 0.98957\n",
      "F1 for LR: 0.0272, RF: 0.4762\n",
      "AUC for LR: 0.5498, RF: 0.9573\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [2, 3, 4]:\n",
    "    # Exclude current decade from training set\n",
    "    concatenate_lists = {\"X\": list(), \"y\": list()}\n",
    "    for j in [2, 3, 4]:\n",
    "        if i != j:\n",
    "            concatenate_lists[\"X\"].append(all_data[f\"{j}_tr\"][\"X\"])\n",
    "            concatenate_lists[\"y\"].append(all_data[f\"{j}_tr\"][\"y\"])\n",
    "    train_X = pd.concat(concatenate_lists[\"X\"])\n",
    "    train_y = pd.concat(concatenate_lists[\"y\"])\n",
    "\n",
    "    test_X = all_data[f\"{i}_test\"][\"X\"]\n",
    "    test_y = all_data[f\"{i}_test\"][\"y\"]\n",
    "\n",
    "    log_reg = LogisticRegression(C=reg, class_weight=\"balanced\").fit(train_X, train_y)\n",
    "    rdm_for = RandomForestClassifier(max_depth=max_depth, class_weight=\"balanced\").fit(train_X, train_y)\n",
    "    log_reg_score = log_reg.score(test_X, test_y)\n",
    "    rdm_for_score = rdm_for.score(test_X, test_y)\n",
    "    log_reg_f1score = f1_score(test_y, log_reg.predict(test_X))\n",
    "    rdm_for_f1score = f1_score(test_y, rdm_for.predict(test_X))\n",
    "    log_reg_auc = roc_auc_score(test_y, log_reg.predict_proba(test_X)[:, 1])\n",
    "    rdm_for_auc = roc_auc_score(test_y, rdm_for.predict_proba(test_X)[:, 1])\n",
    "\n",
    "    print(f\"Decade {i}:\")\n",
    "    print(\"Test on {0}, LR: {1}, RF: {2}\".format(i, round(log_reg_score, 5), round(rdm_for_score, 5)))\n",
    "    print(\"F1 for LR: {0}, RF: {1}\".format(round(log_reg_f1score, 4), round(rdm_for_f1score, 4)))\n",
    "    print(\"AUC for LR: {0}, RF: {1}\\n\".format(round(log_reg_auc, 4), round(rdm_for_auc, 4)))"
   ]
  },
  {
   "source": [
    "# Exp 3: Predicting the future. Test only on future events"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Decade 5:\nTest on 5, LR: 0.73893, RF: 0.97267\nF1 for LR: 0.0348, RF: 0.4314\nAUC for LR: 0.6312, RF: 0.9589\n\n"
     ]
    }
   ],
   "source": [
    "# Train on all training set but the last\n",
    "train_X = pd.concat([\n",
    "    all_data[\"1_tr\"][\"X\"],\n",
    "    all_data[\"2_tr\"][\"X\"],\n",
    "    all_data[\"3_tr\"][\"X\"],\n",
    "    all_data[\"4_tr\"][\"X\"]\n",
    "])\n",
    "\n",
    "train_y = pd.concat([\n",
    "    all_data[\"1_tr\"][\"y\"],\n",
    "    all_data[\"2_tr\"][\"y\"],\n",
    "    all_data[\"3_tr\"][\"y\"],\n",
    "    all_data[\"4_tr\"][\"y\"]\n",
    "])\n",
    "\n",
    "# Test on last test set\n",
    "test_X = all_data[\"5_test\"][\"X\"]\n",
    "test_y = all_data[\"5_test\"][\"y\"]\n",
    "\n",
    "log_reg = LogisticRegression(C=reg, class_weight=\"balanced\").fit(train_X, train_y)\n",
    "rdm_for = RandomForestClassifier(max_depth=max_depth, class_weight=\"balanced\").fit(train_X, train_y)\n",
    "log_reg_score = log_reg.score(test_X, test_y)\n",
    "rdm_for_score = rdm_for.score(test_X, test_y)\n",
    "log_reg_f1score = f1_score(test_y, log_reg.predict(test_X))\n",
    "rdm_for_f1score = f1_score(test_y, rdm_for.predict(test_X))\n",
    "log_reg_auc = roc_auc_score(test_y, log_reg.predict_proba(test_X)[:, 1])\n",
    "rdm_for_auc = roc_auc_score(test_y, rdm_for.predict_proba(test_X)[:, 1])\n",
    "\n",
    "print(f\"Decade 5:\")\n",
    "print(\"Test on 5, LR: {0}, RF: {1}\".format(round(log_reg_score, 5), round(rdm_for_score, 5)))\n",
    "print(\"F1 for LR: {0}, RF: {1}\".format(round(log_reg_f1score, 4), round(rdm_for_f1score, 4)))\n",
    "print(\"AUC for LR: {0}, RF: {1}\\n\".format(round(log_reg_auc, 4), round(rdm_for_auc, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}