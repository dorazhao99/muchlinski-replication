{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# Model parameters\n",
    "reg = 1000\n",
    "max_depth = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = dict()\n",
    "all_decades = [1, 2, 3, 4, 5]\n",
    "\n",
    "for decade in all_decades:\n",
    "    for ver in [\"tr\", \"test\"]:\n",
    "        filename = f\"{decade}_{ver}\"\n",
    "        data = pd.read_csv(f\"decade{filename}.csv\")\n",
    "        all_data[filename] = dict()\n",
    "        all_data[filename][\"X\"] = data.drop(columns=[\"warstds\"])\n",
    "        all_data[filename][\"y\"] = data[\"warstds\"]"
   ]
  },
  {
   "source": [
    "# Baseline: train on all decades, predict on each decade individually"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Decade 1 -- Test Scores for Logistic Regression: 0.1678321678321678, Random Forest: 0.625\nDecade 2 -- Test Scores for Logistic Regression: 0.05757575757575757, Random Forest: 0.4\nDecade 3 -- Test Scores for Logistic Regression: 0.0437375745526839, Random Forest: 0.4117647058823529\nDecade 4 -- Test Scores for Logistic Regression: 0.0359612724757953, Random Forest: 0.2608695652173913\nDecade 5 -- Test Scores for Logistic Regression: 0.0425531914893617, Random Forest: 0.9473684210526316\n"
     ]
    }
   ],
   "source": [
    "# Train on all decades\n",
    "log_reg = LogisticRegression(C=reg, class_weight=\"balanced\")\n",
    "rdm_for = RandomForestClassifier(max_depth=max_depth, class_weight=\"balanced\")\n",
    "for decade in all_decades:\n",
    "    train_X = all_data[f\"{decade}_test\"][\"X\"]\n",
    "    train_y = all_data[f\"{decade}_test\"][\"y\"]\n",
    "    log_reg.fit(train_X, train_y)\n",
    "    rdm_for.fit(train_X, train_y)\n",
    "\n",
    "# Test on each decade individually\n",
    "for decade in all_decades:\n",
    "    test_X = all_data[f\"{decade}_test\"][\"X\"]\n",
    "    test_y = all_data[f\"{decade}_test\"][\"y\"]\n",
    "    log_reg_score = f1_score(test_y, log_reg.predict(test_X))\n",
    "    rdm_for_score = f1_score(test_y, rdm_for.predict(test_X))\n",
    "    print(\"Decade {2} -- Test Scores for Logistic Regression: {0}, Random Forest: {1}\".format(log_reg_score, rdm_for_score, decade))"
   ]
  },
  {
   "source": [
    "# Exp 1: Predict the past. Train on 1960-2000, test on 1945-1959"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "train_X = all_data[\"1_tr\"][\"X\"]\n",
    "train_y = all_data[\"1_tr\"][\"y\"]\n",
    "\n",
    "test_X = all_data[\"1_test\"][\"X\"]\n",
    "test_y = all_data[\"1_test\"][\"y\"]\n",
    "\n",
    "log_reg = LogisticRegression(C=reg, class_weight=\"balanced\").fit(train_X, train_y)\n",
    "log_reg_score = f1_score(test_y, log_reg.predict(test_X))\n",
    "rdm_for = RandomForestClassifier(max_depth=max_depth, class_weight=\"balanced\").fit(train_X, train_y)\n",
    "rdm_for_score = f1_score(test_y, rdm_for.predict(test_X))\n",
    "print(\"Test Scores for Logistic Regression: {0}, Random Forest: {1}\\n\".format(log_reg_score, rdm_for_score))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 262,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Scores for Logistic Regression: 0.15286624203821658, Random Forest: 0.5573770491803278\n\n"
     ]
    }
   ]
  },
  {
   "source": [
    "# Exp 2: Predicting in-between timeframes.\n",
    "- Train on 1945-1959 and 1970-2000, test on 1960-1969\n",
    "- Train on 1945-1969 and 1980-2000, test on 1970-1979\n",
    "- Train on 1945-1979 and 1990-2000, test on 1980-1989"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Decade 2 -- Test Scores for Logistic Regression: 0.042313117066290554, Random Forest: 0.7272727272727272\n",
      "Decade 3 -- Test Scores for Logistic Regression: 0.04341534008683068, Random Forest: 0.7272727272727272\n",
      "Decade 4 -- Test Scores for Logistic Regression: 0.03716216216216216, Random Forest: 0.5454545454545455\n"
     ]
    }
   ],
   "source": [
    "for i in [2, 3, 4]:\n",
    "    train_X = all_data[f\"{i}_tr\"][\"X\"]\n",
    "    train_y = all_data[f\"{i}_tr\"][\"y\"]\n",
    "\n",
    "    test_X = all_data[f\"{i}_test\"][\"X\"]\n",
    "    test_y = all_data[f\"{i}_test\"][\"y\"]\n",
    "\n",
    "    log_reg = LogisticRegression(C=reg, class_weight=\"balanced\").fit(train_X, train_y)\n",
    "    log_reg_score = f1_score(test_y, log_reg.predict(test_X))\n",
    "    rdm_for = RandomForestClassifier(max_depth=max_depth, class_weight=\"balanced\").fit(train_X, train_y)\n",
    "    rdm_for_score = f1_score(test_y, rdm_for.predict(test_X))\n",
    "    print(\"Decade {2} -- Test Scores for Logistic Regression: {0}, Random Forest: {1}\".format(log_reg_score, rdm_for_score, i))"
   ]
  },
  {
   "source": [
    "# Exp 3: Test only on future events"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Scores for Logistic Regression: 0.06607929515418502, Random Forest: 0.5245901639344261\n\n"
     ]
    }
   ],
   "source": [
    "train_X = all_data[\"5_tr\"][\"X\"]\n",
    "train_y = all_data[\"5_tr\"][\"y\"]\n",
    "\n",
    "test_X = all_data[\"5_test\"][\"X\"]\n",
    "test_y = all_data[\"5_test\"][\"y\"]\n",
    "\n",
    "log_reg = LogisticRegression(C=reg, class_weight=\"balanced\").fit(train_X, train_y)\n",
    "log_reg_score = f1_score(test_y, log_reg.predict(test_X))\n",
    "rdm_for = RandomForestClassifier(max_depth=max_depth, class_weight=\"balanced\").fit(train_X, train_y)\n",
    "rdm_for_score = f1_score(test_y, rdm_for.predict(test_X))\n",
    "print(\"Test Scores for Logistic Regression: {0}, Random Forest: {1}\\n\".format(log_reg_score, rdm_for_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}